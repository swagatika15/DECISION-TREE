{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets                                \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(iris.data)                            \n",
    "df.columns = [\"sl\", \"sw\", 'pl', 'pw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find label for a value\n",
    "#if MIN_Value <=val < (m + Mean_Value) / 2 then it is assigned label a\n",
    "#if (m + Mean_Value) <=val < Mean_Value then it is assigned label b\n",
    "#if (Mean_Value) <=val < (Mean_Value + MAX_Value)/2 then it is assigned label c\n",
    "#if (Mean_Value + MAX_Value)/2 <=val <= MAX_Value  then it is assigned label d\n",
    "\n",
    "def label(val, *boundaries):\n",
    "    if (val < boundaries[0]):\n",
    "        return 'a'\n",
    "    elif (val < boundaries[1]):\n",
    "        return 'b'\n",
    "    elif (val < boundaries[2]):\n",
    "        return 'c'\n",
    "    else:\n",
    "        return 'd'\n",
    "\n",
    "#Function to convert a continuous data into labelled data\n",
    "#There are 4 lables  - a, b, c, d\n",
    "def toLabel(df, old_feature_name):\n",
    "    second = df[old_feature_name].mean()\n",
    "    minimum = df[old_feature_name].min()\n",
    "    first = (minimum + second)/2\n",
    "    maximum = df[old_feature_name].max()\n",
    "    third = (maximum + second)/2\n",
    "    return df[old_feature_name].apply(label, args= (first, second, third))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert all columns to labelled data\n",
    "df['sl_labeled'] = toLabel(df, 'sl')\n",
    "df['sw_labeled'] = toLabel(df, 'sw')\n",
    "df['pl_labeled'] = toLabel(df, 'pl')\n",
    "df['pw_labeled'] = toLabel(df, 'pw')\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['sl', 'sw', 'pl', 'pw'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = pd.DataFrame(iris.target)                                  \n",
    "unused_features = list(df.columns)     #list containing all feature names                        \n",
    "y=y1.values\n",
    "x=df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(s,c):                      #funtion to calculate the entropy of a particular node                                          \n",
    "    ent=0\n",
    "    for k in c:\n",
    "        if s!=0:\n",
    "            n=k/s\n",
    "            if n!=0:\n",
    "                ent+=(-n*math.log(n,10))\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_all(ts, s, e):                 #funtion to calculate the info gain and split info of a feature                \n",
    "    info_f=0\n",
    "    split_info=0\n",
    "    for k in range(len(e)):\n",
    "        if s!=0:\n",
    "            info_f+=ts[k]/s*e[k]\n",
    "            split_info+=-(ts[k]/s*math.log((ts[k]/s),10))\n",
    "    return info_f,split_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain(df,f,y):\n",
    "    if f==\"sl_labeled\":                      #values of the feature are placed in a list\n",
    "        sf=list(df[\"sl_labeled\"])\n",
    "    elif f==\"sw_labeled\":\n",
    "        sf=list(df[\"sw_labeled\"])\n",
    "    elif f==\"pl_labeled\":\n",
    "        sf=list(df[\"pl_labeled\"])\n",
    "    else:\n",
    "        sf=list(df[\"pw_labeled\"])\n",
    "        \n",
    "    ts=[]\n",
    "    entro=[]\n",
    "    for i in set(sf):\n",
    "        c0=0\n",
    "        c1=0\n",
    "        c2=0\n",
    "        for j in range(len(y)):\n",
    "            if sf[j]==i:\n",
    "                if y[j]==0:\n",
    "                    c0+=1\n",
    "                elif y[j]==1:\n",
    "                    c1+=1\n",
    "                elif y[j]==2:\n",
    "                    c2+=1\n",
    "        sum_ = c0+c1+c2\n",
    "        ts.append(sum_)                     #ts is a list which contains the sizes of nodes of the current feature(passed to the function)\n",
    "        c=[c0,c1,c2]\n",
    "        en = entropy(sum_,c)                #passing the sum and the counts of classes(0,1,2) to entropy\n",
    "        entro.append(en)                    #list appending entropies of all nodes(a,b,c,d) of of the current feature\n",
    "    a,b=avg_all(ts, sum(ts), entro)         \n",
    "    return a,b                              #returing the info gain and the split info of the current feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_split_f(e, df, y, unused_features):        #function which returns the feature with the max gain ratio for next split\n",
    "    gain_max=-1\n",
    "    gain_max=float(gain_max)\n",
    "    selected=\"\"\n",
    "    if len(unused_features)!=0:\n",
    "        for f in unused_features:                   #iterating over all unused features and finding gain ratio of each\n",
    "            i_f,s_f= gain(df,f,y)                   #i_f is the info gain and s_f is the split info of the feature\n",
    "            info= e-i_f                             #e is the entropy of node which is splitted\n",
    "            gain_ratio= info/s_f\n",
    "            if gain_max <= gain_ratio:\n",
    "                gain_max= gain_ratio\n",
    "                selected=f  \n",
    "        return selected,gain_max                   #returning the feature with its gain ratio upon which the next split has to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_(sg,abcd,df,y,feat):                       #funtion for calculating and printing everything we require (above level 0)      \n",
    "    while unused_features!=[]:\n",
    "        list_=list(df[feat])                       #list of the selected feature values      \n",
    "        for i in abcd:                                   \n",
    "            print(\"Level\",sg)\n",
    "            c0=0\n",
    "            c1=0\n",
    "            c2=0\n",
    "            for j in range(len(y)):                #calculating the count of each class                   \n",
    "                if list_[j]==i:\n",
    "                    if y[j]==0:\n",
    "                        c0+=1\n",
    "                    elif y[j]==1:\n",
    "                        c1+=1\n",
    "                    else:\n",
    "                        c2+=1\n",
    "            c=[c1,c2,c0]\n",
    "            e=entropy(c1+c2+c0,c)                  #calculating entropy                     \n",
    "            print(\"Count of 0 =\",c0)                    \n",
    "            print(\"Count of 1 =\",c1)\n",
    "            print(\"Count of 2 =\",c2)  \n",
    "            print(\"Current Entropy  is =\",e)\n",
    "            if e!=0:                               #if the entropy is not equal to 0, the node isn't pure, further splitting is required (this node will act as root for the split)   \n",
    "                y3=[]                              #y3, df1 stores the new target and new data (for the next split)\n",
    "                df1=df[df[feat]==i]\n",
    "                for p in range(len(list_)):\n",
    "                    if list_[p]==i:\n",
    "                        y3.append(y[p])\n",
    "                if len(unused_features)!=0:        \n",
    "                    unused_features.remove(feat)   #remove the feature which is used for this split\n",
    "                if len(unused_features)==0:\n",
    "                    print(\"No features left to split\")  #if no feature is left for further splitting, 'no features left' is printed\n",
    "                else:                              #if features are left, find the feature with maximum gain ratio for the next split\n",
    "                    feat,ig=next_split_f(e,df1, y3, unused_features)   #it gives the feature with maximum gain ratio\n",
    "                    print(\"Splitting on feature\",\"'\"+feat+\"'\",\"with gain ratio\",ig)          #feature selected\n",
    "            else:                                  #if entropy is 0 we reached a pure node, no splitting is now required\n",
    "                print(\"Reached leaf Node\")\n",
    "            print()\n",
    "        df=df1\n",
    "        y=y3\n",
    "        abcd=set(df[feat])                         #set which contain the unique values in the selected feature\n",
    "        abcd=list(abcd)\n",
    "        abcd.sort()\n",
    "        sg=sg+1\n",
    "        all_(sg,abcd,df,y,feat)                    #calling funtion all_ recursively till all features are used for splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0\n",
      "Count of 0 = 50\n",
      "Count of 1 = 50\n",
      "Count of 2 = 50\n",
      "Current Entropy is = 0.4771212547196624\n",
      "Splitting on feature 'pw_labeled' with gain ratio 0.6996382036222092\n",
      "\n",
      "Level 1\n",
      "Count of 0 = 50\n",
      "Count of 1 = 0\n",
      "Count of 2 = 0\n",
      "Current Entropy  is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 1\n",
      "Count of 0 = 0\n",
      "Count of 1 = 10\n",
      "Count of 2 = 0\n",
      "Current Entropy  is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 1\n",
      "Count of 0 = 0\n",
      "Count of 1 = 40\n",
      "Count of 2 = 16\n",
      "Current Entropy  is = 0.25982518101310587\n",
      "Splitting on feature 'pl_labeled' with gain ratio 0.43340994956210654\n",
      "\n",
      "Level 1\n",
      "Count of 0 = 0\n",
      "Count of 1 = 0\n",
      "Count of 2 = 34\n",
      "Current Entropy  is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 2\n",
      "Count of 0 = 0\n",
      "Count of 1 = 1\n",
      "Count of 2 = 0\n",
      "Current Entropy  is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 2\n",
      "Count of 0 = 0\n",
      "Count of 1 = 39\n",
      "Count of 2 = 8\n",
      "Current Entropy  is = 0.19813531389382344\n",
      "Splitting on feature 'sl_labeled' with gain ratio 0.12674503775809323\n",
      "\n",
      "Level 2\n",
      "Count of 0 = 0\n",
      "Count of 1 = 0\n",
      "Count of 2 = 8\n",
      "Current Entropy  is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 3\n",
      "Count of 0 = 0\n",
      "Count of 1 = 0\n",
      "Count of 2 = 1\n",
      "Current Entropy  is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 3\n",
      "Count of 0 = 0\n",
      "Count of 1 = 14\n",
      "Count of 2 = 0\n",
      "Current Entropy  is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 3\n",
      "Count of 0 = 0\n",
      "Count of 1 = 23\n",
      "Count of 2 = 7\n",
      "Current Entropy  is = 0.23594037110284793\n",
      "Splitting on feature 'sw_labeled' with gain ratio 0.07092036405148884\n",
      "\n",
      "Level 3\n",
      "Count of 0 = 0\n",
      "Count of 1 = 2\n",
      "Count of 2 = 0\n",
      "Current Entropy  is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 4\n",
      "Count of 0 = 0\n",
      "Count of 1 = 3\n",
      "Count of 2 = 1\n",
      "Current Entropy  is = 0.24421905028821553\n",
      "No features left to split\n",
      "\n",
      "Level 4\n",
      "Count of 0 = 0\n",
      "Count of 1 = 14\n",
      "Count of 2 = 6\n",
      "Current Entropy  is = 0.2652949955741215\n",
      "No features left to split\n",
      "\n",
      "Level 4\n",
      "Count of 0 = 0\n",
      "Count of 1 = 6\n",
      "Count of 2 = 0\n",
      "Current Entropy  is = 0.0\n",
      "Reached leaf Node\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c0=len(y[y==0])                                      #calculating the count of each class for level 0          \n",
    "c1=len(y[y==1])\n",
    "c2=len(y[y==2])\n",
    "c=[c1,c2,c0]                                                       \n",
    "e=entropy(c1+c2+c0,c)                                #calculating entropy\n",
    "print(\"Level\",0)                                               \n",
    "print(\"Count of 0 =\",c0)\n",
    "print(\"Count of 1 =\",c1)\n",
    "print(\"Count of 2 =\",c2)\n",
    "print(\"Current Entropy is =\",e)\n",
    "feat,ig=next_split_f(e, df, y, unused_features)      #calling next_split_feat which gives us the feature with the maximum gain ratio for the next split\n",
    "print(\"Splitting on feature\",\"'\"+feat+\"'\",\"with gain ratio\",ig)          #feature selected\n",
    "print()\n",
    "abcd=set(df[feat])                                   #set which contain the unique values in the selected feature          \n",
    "abcd=list(abcd)\n",
    "abcd.sort()                                                     \n",
    "sg=1                                                 #count for the levels       \n",
    "all_(sg,abcd,df,y,feat)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as tree\n",
    "data = datasets.load_iris()                                \n",
    "clf=tree()\n",
    "clf.fit(data.data,data.target)\n",
    "import pydotplus\n",
    "dotdata=export_graphviz(clf,out_file=None,\n",
    "                       feature_names=data.feature_names,class_names=data.target_names)\n",
    "graph=pydotplus.graph_from_dot_data(dotdata)\n",
    "graph.write_pdf('Decision_Tree.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
